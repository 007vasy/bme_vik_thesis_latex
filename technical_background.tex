%----------------------------------------------------------------------------
\chapter{Technical background}
%----------------------------------------------------------------------------
	\section{The MANTIS project}
%----------------------------------------------------------------------------
		\subsection{Overview of the MANTIS project}
%----------------------------------------------------------------------------
MANTIS' proactive service maintenance platform and its associated architecture draw inspiration from the Cyber Physical System approach. Physical systems (e.g. industrial machines, vehicles, renewable energy assets) and the environment they operate in are monitored continuously by a broad and diverse range of intelligent sensors, resulting in massive amounts of data that characterize the usage history, operational condition, location, movement and other physical properties of those systems. These systems form part of a larger network of heterogeneous and collaborative systems (e.g. vehicle fleets or photovoltaic and windmill parks) connected via robust communication mechanisms able to operate in challenging environments.

Sophisticated distributed sensing and decision making functions are performed at different levels in a collaborative way ranging from (i) local nodes that pre-process raw sensor data and extract relevant information before transmitting it, thereby reducing bandwidth requirements of communication, (ii) over intermediate nodes that offer asset-specific analytics to locally optimize performance and maintenance, (iii) to cloud-based platforms that integrate information from ERP, CRM and CMMS systems and execute distributed processing and analytics algorithms for global decision making \cite{Mantis}.

%----------------------------------------------------------------------------
		\subsection{datasets from STILL}
%----------------------------------------------------------------------------
			\subsubsection{CAN fingerprint dataset}
%----------------------------------------------------------------------------
				\paragraph{Phase One: Small Fingerprints - }
				\noindent
As it was mentioned before, STILL forklifts \cite{RX20} use the CAN technology \cite{CAN} to collect data. In my subject project two kinds of datasets are utilized\footnote{Physical sensory and internal electric part logs.}. In the first, called "CAN fingerprint dataset", the workers from the STILL had connected a special CAN bus data collector to one forklift and had done specific tasks with them. They have called them "fingerprints". The *.mat file names helped to understand the type of path\footnote{tracktype\_(with load)/(without load)\_speed} and what the forklift has gone through:

\begin{itemize}[noitemsep]
    \item {800hTestDrive\_fast.mat,}
    \item {800hTestDrive\_slow.mat,}
    \item {FastTrack800h\_fast.mat,}
 	\item {FastTrack800h\_slow.mat,}
	\item {FastTrackEight\_wl\_fast.mat,}
	\item {FastTrackEight\_wl\_slow.mat,}
	\item {FastTrackEight\_wol\_fast.mat,}
	\item {FastTrackEight\_wol\_slow.mat,}
  	\item {FastTrackOval\_wl\_fast.mat,}
	\item {FastTrackOval\_wl\_slow.mat,}
	\item {FastTrackOval\_wol\_fast.mat,}
	\item {FastTrackOval\_wol\_slow.mat,}
	\item {Ramp\_wl\_fast.mat,} 
	\item {Ramp\_wl\_slow.mat,}
	\item {Ramp\_wol\_fast.mat,}
	\item {Ramp\_wol\_slow.mat,}
    \item {WorkCycle\_fast.mat,}
    \item {WorkCycle\_slow.mat,}
	\item {Shunt800h\_fast.mat,}  	
  	\item {Shunt800h\_slow.mat,}
 	\item {Shunt\_fast.mat,} 	
 	\item {Shunt\_slow.mat.}
\end{itemize}

				\subparagraph\noindent
As it easily can be seen in the file names, the workers carried out various tests with the trucks more than one time with various speed and load over various tracks.

However, in this first iteration, STILL did not provide any target value for tire abrasion. Thus from this first iteration I was able to make only exploratory data analysis to fuel further data collection. With enough target values in adequate resolution and quality, predictive models can be trained.

In the second iteration over the data provided on 10.2017 I received more information in a quite similar fashion, but from working forklifts and on top of that with some additional tire measurement. The CAN-bus sensor data contains approximately two months in time, but there were just a few measurements for tire wear from every third week. Unfortunately, this is just nearly sufficient to make predictions, but it was required required for further iterations to develop and upgrade the model.

\#TODO enumerate column names in English.
%----------------------------------------------------------------------------
				\paragraph{Phase Two: Long measurement with additional target values - }
In the second iteration our team was given some additional data from STILL. It included 3 forklifts' CAN bus data with additional tire measurements and a little change in the columns names and values.
				\subparagraph\noindent
With this few tire measurement divided in time, the interpolation and the RUL calculation become possible, despite the high risk of over-fitting \cite{OverFitting} the machine learning model or a statistical model, which could cause the lack of satisfying results.

\#TODO enumerate column names in English.
%----------------------------------------------------------------------------
			\subsubsection{Electrical failure prediction dataset}
%----------------------------------------------------------------------------
The STILL forklift's system has an electrical CAN bus-based, electrical warning-collection subsystem. The warning comes from the part which can communicate with the bus. Engineers of STILL captured this data in a defined time frame and saved it for us in a text\footnote{txt format} file. 

One observation (record) in the previously mentioned file contains an unique ID of the forklift, timestamp, occurred warning and other specific data that isn't in the scope of this thesis.

When considering the full dataset for fault prediction regarding the STILL case, there are two additional files to work with, one is an SAP database export in a txt format, another one is and xls file. Both have truck ID, exchanged part ID, and timestamp in one observation along with additional information what is not in the spectrum of this project.

For the sake of completeness, the last two files have technical worker comments and not all observations have exchanged part ID. For that we can use some Natural Language Processing Methods, but this is also not in the scope of this piece of writing.

From this three previously described files, when it is represented in a tidy, the wanted remaining useful life  - our final, expected result - can be calculated.

\#TODO enumerate column names in English.
%----------------------------------------------------------------------------
	\section{Data processing methods}
%----------------------------------------------------------------------------
		\subsection{CAN fingerprint}
Assuming someone wants to make an educated guess about the future, the neat arrangement of data is demanded. This is often called tidy format, as it is advised and required for preparation for most of data mining methods. For that reasons, I have chosen the R language to achieve this objective.

In this case, the *.mat files involved a special treatment called box-shorting\footnote{Or bucket-short} \cite{Bucketshort} to achieve the clean and usable tidy state. During the box-shorting procedure the researcher has to know the range of shorting key (in this dataset's case the timestamp key's range) and with that, one can make a large data table with the keys and a column with "NA"-s. It is needed to organize multi-frequency sensory data.

Once the tidying is done, the \textit{exploratory} data analysis comes to make sense about the data mass, and develop ways to achieve the best prediction possible, and to short out unnecessary columns to make the future process faster.
%----------------------------------------------------------------------------
		\subsection{Electrical failure prediction}
For knowledge broadation and easy network-like data representation I had chosen Python language, and the Pycharm software \cite{PyCharm} along with NetworkX Python package \cite{NetworkX}.

This is an another coding language useful for data science related to making solutions along with an enormous web community. 

With these tools the processing of the dataset is relative easy and the it is helps to maintain the focus on the algorithm design, and development.
%----------------------------------------------------------------------------
	\section{Development environment}
%----------------------------------------------------------------------------
		\subsection{Hardware}
%----------------------------------------------------------------------------
			\subsubsection{Personal computer}
%----------------------------------------------------------------------------
My PC is a Dell Latitude E6320 64 bit with an Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz processor \cite{Latitude}.
%----------------------------------------------------------------------------
			\subsubsection{Department Linux R and Python server}
%----------------------------------------------------------------------------
The TMIT Department's super computer called "batman" is a Linux based R and Python server, and it is capable of running R and Python scripts on enormous datasets. It has two Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz processors, each of them has 6 cores and is capable of running 12 Threads \cite{Batman}.
%----------------------------------------------------------------------------
		\subsection{Software}
%----------------------------------------------------------------------------
			\subsubsection{Linux Ubuntu 17.04}
%----------------------------------------------------------------------------
The operation system in the title is an open source software, stable and convenient for an advanced user. As a sidenote, it is the easiest way to communicate with a Linux system \cite{Ubuntu} via SSH \cite{SSH}.
%----------------------------------------------------------------------------				
			\subsubsection{RStudio}
%----------------------------------------------------------------------------
RStudio is the most commonly used tool for developing R projects, it has good package controlling application \cite{RStudio}.
%----------------------------------------------------------------------------	
			\subsubsection{Termius Android mobile phone application}
%----------------------------------------------------------------------------
Tidying and data preprocessing method is resource and time consuming. Thus I have optimized it for every-day life with an application via 4G or HSDPA internet access to maintain an SSH connection to the Linux R server. In addition, supervise and check the processes' progress from time to time and handle the occasional errors and bugs \cite{Termius}.
%----------------------------------------------------------------------------
			\subsubsection{Git and GitHub}
%----------------------------------------------------------------------------
As a consequence of version control and open source commitment, I had chosen this common tool set \cite{Github} to control the versions of my work as it has been progressing. The work with the two datasets\footnote{\cite{GitHub_CAN_RUL,GitHub_FP_RUL}} and the documentation in LateX \cite{GitHub_Thesis_Text} are included.
%----------------------------------------------------------------------------
			\subsubsection{PyCharm}
%----------------------------------------------------------------------------
During working with the Electrical failure prediction dataset I had used Python for various reasons, mainly because there is a package called \textit{NetworkX} \cite{NetworkX}. Moreover, for Python development, the most convenient tool is PyCharm because it is high number of useful functions \cite{PyCharm}.	
%----------------------------------------------------------------------------
		\subsection{Management}
%----------------------------------------------------------------------------
According my demand of productivity, I use the GTD \cite{GTD} methodology concluded from 10 years of experience. It provides clarity, focus, and flexible planning for me. Additionally, I implemented it in Wrike \cite{WRIKE} project management software available for students free of charge \cite{WRIKE_for_students}.