%----------------------------------------------------------------------------
\chapter{Technical background}
%----------------------------------------------------------------------------
	\section{The MANTIS project}
%----------------------------------------------------------------------------
		\subsection{Overall picture about the MANTIS project}
%----------------------------------------------------------------------------
The MANTIS pilot project is a data-driven decision making system. The collected information comes from industrial sensors and on a popular IoT communication protocol (MQTT) communicate with the given company cloud service, where the data is being tidied and prediction happens. These processes are providing future insights to the company's employees for pre-maintenance and with that leading to potential reduction of human, financial, and material resources.\cite{Mantis}

%----------------------------------------------------------------------------
		\subsection{Data sets from STILL}
%----------------------------------------------------------------------------
			\subsubsection{CAN fingerprint dataset}
%----------------------------------------------------------------------------
				\paragraph{Phase One}
				\noindent
As it was mentioned before, STILL forklifts \cite{RX20} use the CAN technology to collect data. In this project are two kinds of them is utilized \footnote{Physical sensory and internal electric part logs.}. In the CAN fingerprint data set, the workers from the STILL had connected a special CAN bus data collector to a few forklift and had done with them specific task. They have called it "fingerprints". The *.mat file names helped the understanding the type of the path and what the forklift has gone through:

\begin{itemize}[noitemsep]
    \item {800hTestDrive\_fast.mat}
    \item {800hTestDrive\_slow.mat}
    \item {FastTrack800h\_fast.mat}
 	\item {FastTrack800h\_slow.mat}
	\item {FastTrackEight\_wl\_fast.mat}
	\item {FastTrackEight\_wl\_slow.mat}
	\item {FastTrackEight\_wol\_fast.mat}
	\item {FastTrackEight\_wol\_slow.mat}
  	\item {FastTrackOval\_wl\_fast.mat}
	\item {FastTrackOval\_wl\_slow.mat}
	\item {FastTrackOval\_wol\_fast.mat}
	\item {FastTrackOval\_wol\_slow.mat}
	\item {Ramp\_wl\_fast.mat} 
	\item {Ramp\_wl\_slow.mat}
	\item {Ramp\_wol\_fast.mat}
	\item {Ramp\_wol\_slow.mat}
    \item {WorkCycle\_fast.mat}
    \item {WorkCycle\_slow.mat}
	\item {Shunt800h\_fast.mat}  	
  	\item {Shunt800h\_slow.mat}
 	\item {Shunt\_fast.mat} 	
 	\item {Shunt\_slow.mat}
\end{itemize}\footnote{tracktype\_(with load)/(without load)\_speed}

				\subparagraph\noindent
As it easily can be seen in the file names, the workers carried out various tests with the trucks more than one time with various speed and load on the over various tracks.

However, in this first iteration, STILL did not provide any target value for tire abrasion. So from this first iteration I was able to make only exploratory data analysis to fuel further data collection and with enough target values in sustainable resolution and quality to train some predictive model based on that data.
				\subparagraph\noindent
In the second iteration on data provided on 10.2017 I received more information in a quite similar fashion, but from working forklift, and a top of that with some additional tire measurement. The CAN-bus sensor data encompress approximately two months in time, but there were just a few measurements of the tire wear, from every third week. Unfortunately, this is just nearly enough to make some predictions, but required for further iterations to develop and upgrade the model.

\#TODO enumerate column names in english.
%----------------------------------------------------------------------------
				\paragraph{Phase Two}
In the second iteration our team got some additional data from STILL. It estimated 3 forklifts CAN bus data with additional tire measurement, and a little change in the columns names and values.
				\subparagraph\noindent
With this few tire measurement divided in time, the interpolation and the RUL calculation can be possible, but with high risk of over-fitting the machine learning model or a statistical model with not so satisfying results.
\#TODO enumerate column names in english.
%----------------------------------------------------------------------------
			\subsubsection{Electrical fail prediction dataset}
%----------------------------------------------------------------------------
\paragraph\noindent
The STILL forklift's system has an electrical CAN bus warning collection system. The warning comes from the part what can communicate with the bus. The engineer of the STILL captured this data from a defined time frame and save it for us in a txt file. 

\paragraph\noindent
One observation in the previously mentioned file is involves a forklift unique ID, the time stamp and the occurred warning and some other specific data what isn't in the scope of this thesis.
\paragraph\noindent
In the world of the Electrical fail prediction dataset there is other to file to work with, one is an SAP database export in a txt format and one is and xls file, all two have truck ID, exchanged part ID and time stamp in one observation with more data what is not in the spectrum of this project.
\paragraph\noindent
For the sake of completeness the last two files have technical worker comments and not all observations have exchanged part ID. For that we can use some Natural Language Processing Method but this is also not in the scope of this course.
\paragraph\noindent
From this three previously described file when it's represented in a normally workable way, the wanted remaining useful life can be calculated.

\#TODO enumerate column names in english.
%----------------------------------------------------------------------------
	\section{Data processing methods}
%----------------------------------------------------------------------------
		\subsection{CAN fingerprint}
				\paragraph\noindent
Assuming someone wants to make educated guess about the future, the neat arrangement of data is demanded, often called "tidy" format, as it is advised and required for preparation for most of the data mining methods. And for that reasons I had chosen the R language to tackle this objective.
				\paragraph\noindent
In this case, the *.mat files involved a special treatment called box-shorting to achieve the clean and usable "tidy" state. During the box-shorting procedure mentioned before, the researcher has to know the range of shorting key (in this data set's case the time stamp key's range) and with that, one can make a large data table with a lot of "NA"-s, but it's needed to organize the multi frequency sensory data.

Once the tidying is done, comes the \textit{exploratory} data analysis to make sense about the data mass and come with ways to achieve the best prediction possible, and short out unnecessary columns, to make the future process faster.
%----------------------------------------------------------------------------
		\subsection{Electrical fail prediction}
For knowledge brodation and easy network-like data representing reasons I had chosen the Python language, and the Pycharm software along with the networkx Python package.

It's an another language useful for data science related solution making along with an enormous web community.
%----------------------------------------------------------------------------
	\section{Developing tools}
%----------------------------------------------------------------------------
		\subsection{Hardware}
%----------------------------------------------------------------------------
			\subsubsection{Personal computer}
%----------------------------------------------------------------------------
My PC is a Dell Latitude E6320 64 bit with an Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz processor.
\cite{Latitude}
%----------------------------------------------------------------------------
			\subsubsection{Department Linux R and Python server}
%----------------------------------------------------------------------------
The Department's super computer called "batman" is Linux based R and Python server and it's capable of running R and Python script's on enormous data set's. It has two Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz processors, each of them has 6 cores and is capable of running 12 Threads.
\cite{Batman}
%----------------------------------------------------------------------------
		\subsection{Software}
%----------------------------------------------------------------------------
			\subsubsection{Linux Ubuntu 17.04}
%----------------------------------------------------------------------------
The operation system in the title is an open source software, stable and convenient for an advanced user, and to go further, it's the easiest way to communicate with to Linux system via SSH.
\cite{Ubuntu}
%----------------------------------------------------------------------------				
			\subsubsection{RStudio}
%----------------------------------------------------------------------------
RStudio is the most common tool for developing R projects, it has good package controlling application.
\cite{RStudio}
%----------------------------------------------------------------------------	
			\subsubsection{Termius Android mobile phone application}
%----------------------------------------------------------------------------
The tidying and data preprocessing method is resource and time consuming, thus I have optimized it for every-day life with an application via 4G or HSDPA internet access to maintain an SSH connection to the Linux R server. In addition supervise and check the process's progress from time to time and hand the occasional errors and bugs.
\cite{Termius}
%----------------------------------------------------------------------------
			\subsubsection{Git and GitHub}
%----------------------------------------------------------------------------
As a consequence of version control and open source commitment, I had chosen this common tool set to save my work as it has been progressing.
\cite{Github}
%----------------------------------------------------------------------------
			\subsubsection{PyCharm}
%----------------------------------------------------------------------------
At working with the Electrical fail prediction data set, I had used python for various reasons, mainly because there is a package called \textit{NetworkX} \cite{NetworkX}, and for python developing for me the most convenient tool is PyCharm because it's high functionality.
\cite{PyCharm}	
%----------------------------------------------------------------------------
		\subsection{Management}
%----------------------------------------------------------------------------
according my demand of productivity, I use the GTD\cite{GTD} methodology, it's a conclusion of 10 years of experience. It provides clarity, focus and flexible planning for me. Additionally, I implemented it in Wrike \cite{WRIKE} project management software available for students for free. For more information visit the developer company's support website: \cite{WRIKE_for_students}